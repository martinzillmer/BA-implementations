{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72b4ec6d",
   "metadata": {},
   "source": [
    "#### The content of this file is based on: https://github.com/pescap/HPOMax/blob/main/HPO-PINNs/Dirichlet/HPO-2D.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c864fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.insert(0,'/root/shared/nans/deepxde')\n",
    "\n",
    "import skopt\n",
    "import seaborn as sns\n",
    "from model_gp import fitness\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9309ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost as function of depth and length\n",
    "def formula(N , L):\n",
    "    return N * (2+ 1) + (L-2) * N * (N + 1) + (N+1) \n",
    "\n",
    "\n",
    "def parse_results(name):\n",
    "    search_result = skopt.load(name + '.pkl')       # load search_result\n",
    "    n_calls = search_result.func_vals.shape[0]      # get n_calls\n",
    "    test = []\n",
    "    metric = []\n",
    "    train = []\n",
    "    texec = []\n",
    "\n",
    "    # append results from all configs\n",
    "    for i in range(n_calls):\n",
    "        temp_name = name + '-'  + str(i) \n",
    "        train.append(skopt.load(temp_name + 'train.pkl'))\n",
    "        test.append(skopt.load(temp_name + 'test.pkl')) \n",
    "        metric.append(skopt.load(temp_name + 'metric.pkl'))\n",
    "        texec.append(skopt.load(temp_name + 'texec.pkl'))      \n",
    "\n",
    "    # allocate\n",
    "    min_train = np.zeros(n_calls)\n",
    "    min_test = np.zeros(n_calls)\n",
    "    min_metric = np.zeros(n_calls)\n",
    "\n",
    "    # Find mest values for each config\n",
    "    for i in range(n_calls):\n",
    "        imin = test[i].argmin()\n",
    "        min_train[i] = train[i][imin]\n",
    "        min_test[i] = test[i][imin]\n",
    "        min_metric[i] = metric[i][imin]\n",
    "\n",
    "    # create dataframe of best values\n",
    "    df1 = pd.DataFrame(np.column_stack([min_train, min_test, min_metric, texec]), columns = ['train', 'test', 'metric', 'texec'])\n",
    "\n",
    "    # Remove nan in metric\n",
    "    max_train = df1[~np.isnan(df1.train)].max()\n",
    "    max_test =  df1[~np.isnan(df1.test)].max()\n",
    "    max_metric = df1[~np.isnan(df1.metric)].max()\n",
    "    \n",
    "    # Set nan values to max\n",
    "    df1[np.isnan(df1.train)] = max_train\n",
    "    df1[np.isnan(df1.test)] = max_test\n",
    "    df1[np.isnan(df1.metric)] = max_metric\n",
    "\n",
    "\n",
    "    # Create dataframe of all configs\n",
    "    df0 = pd.DataFrame(search_result.x_iters, columns=['lr', 'd', 'w', 'a']) \n",
    "    df0['f'] = search_result.func_vals.astype(float)        # function values for each iteration\n",
    "    df0['global_index'] = np.arange(df0.shape[0])           # Configuration number\n",
    "\n",
    "    # Information: learning rate, depth, width, activation\n",
    "    df0['information'] = '[' +df0.lr.map(lambda x : \"{:.2e}\".format(x)).astype(str)+ ',' + df0.d.astype(str) + ','+ df0.w.astype(str)+ ',' + df0.a.astype(str) + ']'\n",
    "    df0['cost'] = formula(df0.w, df0.d + 1)     # cost:  ???\n",
    "    \n",
    "    # Concatenate data frames\n",
    "    df2 = pd.concat([df0, df1], axis = 1)\n",
    "    \n",
    "    # allocate\n",
    "    conv = np.zeros(n_calls)\n",
    "    conv_metric = np.zeros(n_calls)\n",
    "    \n",
    "    # Conv, conv_metric columns\n",
    "    for i in range(n_calls):\n",
    "        conv[i] = df2.f.values[:i + 1].min()\n",
    "        conv_metric[i] = df2.metric.values[:i + 1].min()\n",
    "    df2['conv'] = conv\n",
    "    df2['conv_metric'] = conv_metric\n",
    "    \n",
    "    # if f == 100k we just take the max value\n",
    "    df2.loc[df2.f == 100000, 'f'] = df2.f[df2.f != 100000].max()\n",
    "    #df2.loc[df2.f == 100000, 'train'] = df2.train[df2.f != 100000].max()\n",
    "    #df2.loc[df2.f == 100000, 'test'] = df2.test[df2.f != 100000].max()\n",
    "    \n",
    "    # sort by function values\n",
    "    df = df2.sort_values(['f'], ascending = [True])\n",
    "\n",
    "    # Convert types and format\n",
    "    df['cost'] = df['cost'].astype(float)\n",
    "    df[['global_index','f']] = df[['global_index','f']].astype(float)\n",
    "    df['f'] = df['f'].astype(float)\n",
    "    df['f_format'] = df.f.map(lambda x : \"{:.2e}\".format(x)).astype(str)\n",
    "    df['cost_format'] = df.cost.map(lambda x : \"{:.2e}\".format(x)).astype(str)\n",
    "    \n",
    "    return df, train, test, metric\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64a1cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'results/burgersgp'\n",
    "\n",
    "n_calls = 11\n",
    "df, trainF, testF, metricF = parse_results(name)\n",
    "\n",
    "# new columns\n",
    "df['local_index'] = (np.arange(n_calls) + 1).astype(int)    # index here\n",
    "df['log10f'] = np.log10(df.f)                               # log10 transform of f\n",
    "df['log10metric'] = np.log10(df.metric)                     # log10 transform of metric\n",
    "df['log10train'] = np.log10(df.train)                       # log10 transform of train\n",
    "df['log10test'] = np.log10(df.test)                         # log10 transform of test\n",
    "df['log10conv'] = np.log10(df.conv)                         # log10 transform of conv\n",
    "df['log10conv_metric'] = np.log10(df.conv_metric)           # log10 transform of conv_metric\n",
    "\n",
    "search_result = skopt.load(name + '.pkl')                   # load search_result\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0307aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "melt1 = df.melt(id_vars =['local_index'], value_vars =  ['log10train', 'log10test'])\n",
    "melt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e97e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "melt1 = df.melt(id_vars =['global_index'], value_vars =  ['log10conv','log10conv_metric'])\n",
    "melt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a74b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\",{'axes.grid' : True})\n",
    "\n",
    "# 1 row with 2 plots\n",
    "fig, (ax1, ax2) = plt.subplots(1,2 , sharey=True, figsize= (12, 5))\n",
    "\n",
    "g = sns.pointplot(data = melt1, \n",
    "                 x = 'local_index',                                   \n",
    "                 palette = sns.color_palette('rocket_r', n_colors=3), # colors\n",
    "                 y = 'value',\n",
    "                 scale = .8,#, s = 80, lw = 2,\n",
    "                 hue='variable',\n",
    "                 ax = ax1) # plug into ax1\n",
    "                 \n",
    "#ax.set_xlabel(r'$\\lambda_{M-m}^+$ Ranking')\n",
    "#ax1.set_title(r'$\\log_{10}\\left(\\mathcal{L}^\\cdot_{\\theta_K^+}[\\lambda_{M-m}^+]\\right)$', fontsize=16)\n",
    "\n",
    "# title\n",
    "ax1.set_title(r'$\\log_{10}($loss$^\\cdot[\\lambda])$', fontsize=16)\n",
    "\n",
    "# labels\n",
    "ax1.set_ylabel(r'')\n",
    "ax1.set_xlabel(r'Ranking', fontsize=16)\n",
    "\n",
    "ax1.set_xlim(-1,12)                 # axis length\n",
    "xticks = np.array([0, 3, 6, 9])     # ticks on x-axis\n",
    "ax1.grid()                          # grid\n",
    "labels = ax1.get_xticklabels()      # get x labels\n",
    "\n",
    "ax1.set_xticks(xticks)\n",
    "a = (xticks + 1).astype(str)\n",
    "b = ['#' + s for s in list(a)]\n",
    "ax1.set_xticklabels(b, fontsize= 14)\n",
    "#ax1.set_yticklabels(labelsy, fontsize= 14)\n",
    "ax1.xaxis.grid(color='gray', linestyle='dashed')\n",
    "ax1.yaxis.grid(color='gray', linestyle='dashed')\n",
    "#ax.tick_params(axis='both', which='major')\n",
    "#title = ax.get_title()\n",
    "\n",
    "\n",
    "handles, labels = ax1.get_legend_handles_labels() \n",
    "\n",
    "labels = ['train', 'test', 'metric']\n",
    "legend = ax1.legend(loc = 'lower right', handles = handles, labels = labels, title = 'Plot:', fontsize=14)  \n",
    "legend.get_title().set_fontsize('14')\n",
    "\n",
    "# AX2\n",
    "\n",
    "g = sns.pointplot(data = melt2, x = 'global_index', \n",
    "                 palette = sns.color_palette('rocket_r', n_colors=3)[1:3], \n",
    "                 y = 'value',\n",
    "                 scale = .8,#, s = 80, lw = 2,\n",
    "                 hue='variable',\n",
    "                 ax = ax2)\n",
    "ax2.set_xlabel(r'Iteration $m$', fontsize=16)\n",
    "\n",
    "ax2.set_title(r'$\\log_{10}($loss$^\\cdot[\\lambda^+_m])$', fontsize=16)\n",
    "#ax2.set_title(r'$\\log_{10}\\left(\\mathcal{L}^\\cdot_{\\theta_K^+}[\\lambda_{m}^+]\\right)$', fontsize=16)\n",
    "ax2.set_ylabel(r'')\n",
    "\n",
    "xticks = np.arange(0,10,2)\n",
    "\n",
    "ax2.grid()\n",
    "ax2.set_xlim(-1,12)\n",
    "\n",
    "labels = ax2.get_xticklabels() # get x labels\n",
    "labelsy = ax1.get_yticklabels() # get x labels\n",
    "\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "\n",
    "ax2.set_xticks(xticks)\n",
    "ax2.set_xticklabels((xticks).astype(str), fontsize=14)\n",
    "\n",
    "ax2.xaxis.grid(color='gray', linestyle='dashed')\n",
    "ax2.yaxis.grid(color='gray', linestyle='dashed')\n",
    "#title = ax.get_title()\n",
    "\n",
    "\n",
    "handles, labels = ax2.get_legend_handles_labels() \n",
    "\n",
    "labels = ['test', 'metric']\n",
    "legend = ax2.legend(loc = 'upper right', handles = handles, labels = labels, title = 'Plot:',fontsize =14)  \n",
    "legend.get_title().set_fontsize('14')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0.075, hspace=0.075)\n",
    "\n",
    "plt.savefig('plots/s01.pdf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb3da727",
   "metadata": {},
   "source": [
    "# Partial dependence plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d7db3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_objective, plot_evaluations\n",
    "#from matplotlib import pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "test = plot_objective(search_result, plot_dims = ['learning_rate', 'num_dense_nodes', 'num_dense_layers', 'activation'], show_points=True, size =3.8, cmap = 'rocket_r')\n",
    "\n",
    "plt.savefig('plots/s03.pdf', bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e7d7202",
   "metadata": {},
   "source": [
    "# Parameter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c17c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmin, fmax = df.f.min(), df.f.max()\n",
    "cmin, cmax = df.cost.min(), df.cost.max()\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (6,17), gridspec_kw={'width_ratios': [1,1.5]})\n",
    "g =  sns.heatmap(df[['train']], annot =df[['f_format']], fmt = '' , cmap = 'rocket_r', ax = ax1, cbar_kws = dict(use_gridspec=False,location=\"left\"), cbar = None, xticklabels = [r'$\\mathcal{L}(\\theta_K^\\star, \\lambda_n)$'])\n",
    "g =  sns.heatmap(df[['cost']], annot =df[['information']], fmt = '' , cmap = 'rocket_r', ax = ax2, cbar = None, xticklabels = [r'$|\\Theta|$'])\n",
    "ax1.xaxis.tick_bottom() # x axis on top\n",
    "\n",
    "#ax1.xaxis.set_label_position('top')\n",
    "\n",
    "\n",
    "ax2.xaxis.tick_bottom() # x axis on top\n",
    "\n",
    "plt.savefig('plots/s04.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d4e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the colorbar\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, figsize = (15,8))\n",
    "\n",
    "g =  sns.heatmap(df[['f']], annot =df[['f_format']], fmt = '' , cmap = 'rocket_r', ax = ax1, cbar_kws = dict(use_gridspec=False, orientation = \"horizontal\", format = '%.2e'), cbar = True, xticklabels = [r'$\\mathcal{L}(\\theta_K^\\star, \\lambda_n)$'], cbar_ax =ax2)\n",
    "g =  sns.heatmap(df[['cost']], annot =df[['information']], fmt = '' , cmap = 'rocket_r', ax = ax3, cbar = True, xticklabels = [r'$|\\Theta|$'], cbar_kws = dict(use_gridspec=False, orientation = \"horizontal\", format = '%.2e'), cbar_ax=ax4)\n",
    "\n",
    "#plt.savefig('plots/s05.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831ddc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('fmin-fmax', fmin, fmax)\n",
    "print('cmin-cmax', cmin, cmax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4bf84610",
   "metadata": {},
   "source": [
    "# Convergence of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdba02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index = 0\n",
    "dfbest = pd.DataFrame(np.column_stack([np.arange(trainF[index].shape[0]) * 1000, np.log10(trainF[index]), np.log10(testF[index]),np.log10(metricF[index])]), columns = ['epoch', 'train', 'test', 'metric'])    \n",
    "\n",
    "melt = dfbest.melt(id_vars = ['epoch'], value_vars = ['train', 'test', 'metric'])\n",
    "\n",
    "\n",
    "sns.set_style(\"ticks\",{'axes.grid' : True})\n",
    "\n",
    "fig, ax = plt.subplots(figsize= (8,5))\n",
    "\n",
    "g = sns.pointplot(data = melt, x = 'epoch', \n",
    "                 palette = sns.color_palette('rocket_r', n_colors=3), \n",
    "                 y = 'value',\n",
    "                 scale = .8,# s = 80, lw = 2,\n",
    "                 hue='variable',\n",
    "                 ax = ax)\n",
    "                 \n",
    "                 \n",
    "ax.set_xlabel(r'epoch $k$', fontsize=  16)\n",
    "ax.set_title(r'$\\log_{10}( $loss$^\\cdot[\\lambda_{97}])$', fontsize=16)\n",
    "\n",
    "#ax2.set_title(r'$\\log_{10}($loss$^\\cdot[\\lambda^+_m])$', fontsize=16)\n",
    "\n",
    "#xticks = np.array([0, 10000, 20000, 30000, 40000, 50000])#+1\n",
    "\n",
    "xticks = np.array([0, 10, 20, 30, 40, 50])\n",
    "xlabels = ['0', '10,000', '20,000', '30,000', '40,000', '50,000']\n",
    "ax.set_xlim(-2,52)\n",
    "\n",
    "ax.grid()\n",
    "\n",
    "#labels = ax.get_xticklabels() # get x labels\n",
    "ax.set_ylabel(r'', fontsize=  16)\n",
    "\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xlabels)\n",
    "ax.xaxis.grid(color='gray', linestyle='dashed')\n",
    "ax.yaxis.grid(color='gray', linestyle='dashed')\n",
    "#ax.tick_params(axis='both', which='major')\n",
    "title = ax.get_title()\n",
    "\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels() \n",
    "\n",
    "labels = ['train', 'test', 'metric']\n",
    "legend = ax.legend(loc = 'upper right', handles = handles, labels = labels, title = 'Plot', fontsize =14)\n",
    "legend.get_title().set_fontsize('14')\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "plt.savefig('plots/s12.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bed4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
