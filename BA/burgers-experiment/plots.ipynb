{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72b4ec6d",
   "metadata": {},
   "source": [
    "#### The content in this file is based on: https://github.com/pescap/HPOMax/blob/main/HPO-PINNs/Dirichlet/HPO-2D.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c864fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt\n",
    "import seaborn as sns\n",
    "from model_gp import fitness\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9309ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost as function of depth and length\n",
    "def formula(N , L):\n",
    "    return N * (2+ 1) + (L-2) * N * (N + 1) + (N+1) \n",
    "\n",
    "\n",
    "def parse_results(name):\n",
    "    search_result = skopt.load(name + '.pkl')       # load search_result\n",
    "    n_calls = search_result.func_vals.shape[0]      # get n_calls\n",
    "    test = []\n",
    "    metric = []\n",
    "    train = []\n",
    "    texec = []\n",
    "\n",
    "    # append results from all configs\n",
    "    for i in range(n_calls):\n",
    "        temp_name = name + '-'  + str(i) \n",
    "        train.append(skopt.load(temp_name + 'train.pkl'))\n",
    "        test.append(skopt.load(temp_name + 'test.pkl')) \n",
    "        metric.append(skopt.load(temp_name + 'metric.pkl'))\n",
    "        texec.append(skopt.load(temp_name + 'texec.pkl'))      \n",
    "\n",
    "    # allocate\n",
    "    min_train = np.zeros(n_calls)\n",
    "    min_test = np.zeros(n_calls)\n",
    "    min_metric = np.zeros(n_calls)\n",
    "\n",
    "    # Find mest values for each config\n",
    "    for i in range(n_calls):\n",
    "        imin = test[i].argmin()\n",
    "        min_train[i] = train[i][imin]\n",
    "        min_test[i] = test[i][imin]\n",
    "        min_metric[i] = metric[i][imin]\n",
    "\n",
    "    # create dataframe of best values\n",
    "    df1 = pd.DataFrame(np.column_stack([min_train, min_test, min_metric, texec]), columns = ['train', 'test', 'metric', 'texec'])\n",
    "    print(df1)\n",
    "    # Remove nan in metric\n",
    "    max_train = df1[~np.isnan(df1.train)].max()\n",
    "    max_test =  df1[~np.isnan(df1.test)].max()\n",
    "    max_metric = df1[~np.isnan(df1.metric)].max()\n",
    "    \n",
    "    # Set nan values to max\n",
    "    df1[np.isnan(df1.train)] = max_train\n",
    "    df1[np.isnan(df1.test)] = max_test\n",
    "    df1[np.isnan(df1.metric)] = max_metric\n",
    "\n",
    "\n",
    "    # Create dataframe of all configs\n",
    "    df0 = pd.DataFrame(search_result.x_iters, columns=['lr', 'd', 'w', 'a']) \n",
    "    df0['f'] = search_result.func_vals.astype(float)        # function values for each iteration\n",
    "    df0['global_index'] = np.arange(df0.shape[0])           # Configuration number\n",
    "\n",
    "    # Information: learning rate, depth, width, activation\n",
    "    df0['information'] = '[' +df0.lr.map(lambda x : \"{:.2e}\".format(x)).astype(str)+ ',' + df0.d.astype(str) + ','+ df0.w.astype(str)+ ',' + df0.a.astype(str) + ']'\n",
    "    df0['cost'] = formula(df0.w, df0.d + 1)  \n",
    "    \n",
    "    # Concatenate data frames\n",
    "    df2 = pd.concat([df0, df1], axis = 1)\n",
    "    \n",
    "    # allocate\n",
    "    conv = np.zeros(n_calls)\n",
    "    conv_metric = np.zeros(n_calls)\n",
    "    \n",
    "    # Conv, conv_metric columns\n",
    "    for i in range(n_calls):\n",
    "        conv[i] = df2.f.values[:i + 1].min()\n",
    "        conv_metric[i] = df2.metric.values[:i + 1].min()\n",
    "    df2['conv'] = conv\n",
    "    df2['conv_metric'] = conv_metric\n",
    "    \n",
    "    df2.loc[df2.f == 100000, 'f'] = df2.f[df2.f != 100000].max()\n",
    "    \n",
    "    # sort by function values\n",
    "    df = df2.sort_values(['f'], ascending = [True])\n",
    "\n",
    "    # Convert types and format\n",
    "    df['cost'] = df['cost'].astype(float)\n",
    "    df[['global_index','f']] = df[['global_index','f']].astype(float)\n",
    "    df['f'] = df['f'].astype(float)\n",
    "    df['f_format'] = df.f.map(lambda x : \"{:.2e}\".format(x)).astype(str)\n",
    "    df['cost_format'] = df.cost.map(lambda x : \"{:.2e}\".format(x)).astype(str)\n",
    "    \n",
    "    return df, train, test, metric\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64a1cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'results/burgersgp'\n",
    "\n",
    "n_calls = 30\n",
    "df, trainF, testF, metricF = parse_results(name)\n",
    "\n",
    "# new columns\n",
    "df['local_index'] = (np.arange(n_calls) + 1).astype(int)    # index here\n",
    "df['log10f'] = np.log10(df.f)                               # log10 transform of f\n",
    "df['log10metric'] = np.log10(df.metric)                     # log10 transform of metric\n",
    "df['log10train'] = np.log10(df.train)                       # log10 transform of train\n",
    "df['log10test'] = np.log10(df.test)                         # log10 transform of test\n",
    "df['log10conv'] = np.log10(df.conv)                         # log10 transform of conv\n",
    "df['log10conv_metric'] = np.log10(df.conv_metric)           # log10 transform of conv_metric\n",
    "\n",
    "search_result = skopt.load(name + '.pkl')                   # load search_result\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a74b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "melt1 = df.melt(id_vars =['local_index'], value_vars =  ['log10train', 'log10test'])\n",
    "melt2 = df.melt(id_vars =['global_index'], value_vars =  ['log10conv','log10conv_metric'])\n",
    "sns.set_style(\"ticks\",{'axes.grid' : True})\n",
    "\n",
    "# 1 row with 2 plots\n",
    "fig, (ax1, ax2) = plt.subplots(1,2 , sharey=True, figsize= (12, 5))\n",
    "\n",
    "g = sns.pointplot(data = melt1, \n",
    "                 x = 'local_index',                                   \n",
    "                 palette = [\"blue\",\"red\"], # colors\n",
    "                 y = 'value',\n",
    "                 scale = .8,#, s = 80, lw = 2,\n",
    "                 hue='variable',\n",
    "                 ax = ax1) # plug into ax1\n",
    "                 \n",
    "\n",
    "# title\n",
    "ax1.set_title(r'Sorted by PDE loss', fontsize=16)\n",
    "\n",
    "# labels\n",
    "ax1.set_ylabel(r'$\\log_{10}($loss$[\\lambda])$', fontsize=13)\n",
    "ax1.set_xlabel(r'Ranking', fontsize=16)\n",
    "\n",
    "ax1.set_xlim(0,30)                 # axis length\n",
    "xticks = np.arange(0,30,3)    # ticks on x-axis\n",
    "ax1.grid()                          # grid\n",
    "labels = ax1.get_xticklabels()      # get x labels\n",
    "\n",
    "ax1.set_xticks(xticks)\n",
    "a = (xticks + 1).astype(str)\n",
    "b = ['#' + s for s in list(a)]\n",
    "ax1.set_xticklabels(b, fontsize= 14)\n",
    "ax1.xaxis.grid(color='gray', linestyle='dashed')\n",
    "ax1.yaxis.grid(color='gray', linestyle='dashed')\n",
    "\n",
    "handles, labels = ax1.get_legend_handles_labels() \n",
    "\n",
    "labels = [r'PDE + $\\nabla$PDE loss', 'PDE loss',]\n",
    "legend = ax1.legend(loc = 'lower right', handles = handles, labels = labels, title = 'Plot:', fontsize=14)  \n",
    "legend.get_title().set_fontsize('14')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# AX2\n",
    "\n",
    "g = sns.pointplot(data = melt2, x = 'global_index', \n",
    "                 palette =[\"red\"] ,\n",
    "                 y = 'value',\n",
    "                 scale = .8,#, s = 80, lw = 2,\n",
    "                 hue='variable',\n",
    "                 ax = ax2)\n",
    "ax2.set_xlabel(r'Iteration $m$', fontsize=16)\n",
    "\n",
    "\n",
    "ax2.set_title(r'Convergence', fontsize=16)\n",
    "ax2.set_ylabel(r'$\\log_{10}($loss$^\\cdot[\\lambda^+_m])$', fontsize=14)\n",
    "ax2.grid()\n",
    "\n",
    "xticks = np.arange(1,30,3)\n",
    "\n",
    "labels = ax2.get_xticklabels() # get x labels\n",
    "labelsy = ax1.get_yticklabels() # get x labels\n",
    "\n",
    "ax1.tick_params(axis='both', which='major', labelsize=13)\n",
    "\n",
    "ax2.set_xticks(xticks)\n",
    "ax2.set_xticklabels((xticks).astype(str), fontsize=14)\n",
    "\n",
    "ax2.xaxis.grid(color='gray', linestyle='dashed')\n",
    "ax2.yaxis.grid(color='gray', linestyle='dashed')\n",
    "#title = ax.get_title()\n",
    "\n",
    "\n",
    "handles, labels = ax2.get_legend_handles_labels() \n",
    "\n",
    "labels = ['PDE loss']\n",
    "legend = ax2.legend(loc = 'upper right', handles = handles, labels = labels, title = 'Plot:',fontsize =14)  \n",
    "legend.get_title().set_fontsize('14')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0.075, hspace=0.075)\n",
    "\n",
    "plt.savefig('plots/burgers_hypopt_result.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9561d874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c956ebe",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2266afa5",
   "metadata": {},
   "source": [
    "Restore best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd01277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepxde as dde\n",
    "if dde.backend.backend_name == \"pytorch\":\n",
    "    sin = dde.backend.pytorch.sin\n",
    "    exp = dde.backend.pytorch.exp\n",
    "else:\n",
    "    from deepxde.backend import tf\n",
    "    sin = tf.sin\n",
    "    exp = tf.exp\n",
    "\n",
    "# IC + BC\n",
    "def output_transform(x, y):\n",
    "    x_in = x[:, 0:1]\n",
    "    t_in = x[:, 1:2]\n",
    "\n",
    "    return (1 - x_in) * (1 + x_in) * (1 - exp(-t_in)) * y - sin(np.pi * x_in)\n",
    "\n",
    "# gPINN\n",
    "def pde(x, y):\n",
    "    dy_x = dde.grad.jacobian(y, x, j=0)\n",
    "    dy_t = dde.grad.jacobian(y, x, j=1)\n",
    "    dy_xx = dde.grad.hessian(y, x, i=0, j=0)\n",
    "\n",
    "    dy_tx = dde.grad.hessian(y, x, i=0, j=1)\n",
    "    dy_xxx = dde.grad.jacobian(dy_xx, x, j=0)\n",
    "\n",
    "    dy_tt = dde.grad.hessian(y, x, i=1, j=1)\n",
    "    dy_xxt = dde.grad.jacobian(dy_xx, x, j=1)\n",
    "    return [\n",
    "        dy_t + y * dy_x - 0.01 / np.pi * dy_xx,\n",
    "        dy_tx + (dy_x * dy_x + y * dy_xx) - 0.01 / np.pi * dy_xxx,\n",
    "        dy_tt + dy_t * dy_x + y * dy_tx - 0.01 / np.pi * dy_xxt,\n",
    "    ]\n",
    "\n",
    "\n",
    "geom = dde.geometry.Interval(-1, 1)\n",
    "timedomain = dde.geometry.TimeDomain(0, 1)\n",
    "geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
    "\n",
    "# Data\n",
    "data = dde.data.TimePDE(\n",
    "    geomtime, \n",
    "    pde, \n",
    "    [], \n",
    "    num_domain=config.num_domain, \n",
    ")\n",
    "\n",
    "### must be filled according to best model\n",
    "net = dde.maps.FNN(\n",
    "    [3] + [--fill--] * --fil-- + [3],\n",
    "    \"tanh\",\n",
    "    \"Glorot normal\",\n",
    "\n",
    "\n",
    "model = dde.Model(data, net) \n",
    "model.compile(\"adam\", lr=config.learning_rate)\n",
    "\n",
    "### best model must be specified\n",
    "model.restore(r\"models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eaf5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_testdata():\n",
    "    data = np.load(\"Burgers.npz\")\n",
    "    t, x, exact = data[\"t\"], data[\"x\"], data[\"usol\"].T\n",
    "    xx, tt = np.meshgrid(x, t)\n",
    "    X = np.vstack((np.ravel(xx), np.ravel(tt))).T\n",
    "    y = exact.flatten()[:, None]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5460e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true, y_true = gen_testdata()\n",
    "y_pred = model.predict(x_true)\n",
    "err = np.abs(y_pred - y_true)\n",
    "max_err = err.max()\n",
    "avg_err = err.mean()\n",
    "max_err, avg_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f10590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.tricontourf(x_true[:,0], x_true[:,1], err.reshape(-1), levels=400)\n",
    "plt.colorbar(label=\"absolute error\")\n",
    "plt.scatter(data.anchors[:,0],data.anchors[:,1], s=2, label=\"anchors\", color=\"green\")\n",
    "plt.xlabel(\"x\", fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel(\"t\", fontsize=16)\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(0,1)\n",
    "plt.title(\"Prediction error and RAR points\")\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout(w_pad=0)\n",
    "plt.savefig(\"burgers_error_anchors.png\",\n",
    "            facecolor=\"white\",\n",
    "            pad_inches=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
